../../../pebblesdb/release/db_bench --db=/mnt/hotdb_test/pebbles10B/ycsb_mem64_1.2_3 --num=1000000000 --value_size=128 --batch_size=1000 --benchmarks=fillzipf,stats --data_file=/home/jeff-wang/workloads/zipf1.2_keys10.0B.csv --logpath=/mnt/logs --bloom_bits=10 --log=1 --cache_size=8388608 --open_files=40000 --mem_log_file=/home/jeff-wang/WorkloadAnalysis/comparedDBs/performance_test_scripts/pebblesdb_scripts/10B_Pebblesdb_zipf_hot_removal/Pebblesdb_memory_64MiB_10B_key16_val128_zipf1.2.log --compression=0 --stats_interval=100000000 --histogram=1 --write_buffer_size=1048576 --max_file_size=1048576 --print_wa=true 
Keys:       16 bytes each
Values:     128 bytes each (64 bytes after compression)
Entries:    1000000000
RawSize:    137329.1 MB (estimated)
FileSize:   76293.9 MB (estimated)
WARNING: Snappy compression is not enabled
------------------------------------------------
Recover Time : 18446744073709545385
InitializeFileLevelBloomFilter Time: 2
InitializeTableCacheFileMetaData Time: 2
PebblesDB Open Time: 27177
Write buffer: 1024.00 KB
Recover Time : 18446744073709455625
InitializeFileLevelBloomFilter Time: 1
InitializeTableCacheFileMetaData Time: 2
PebblesDB Open Time: 250538
start benchmarking num_ = 1000000000 entries(batches:1) in DoWrite_zipf()
2024/11/20-00:53:04  ... thread 0: (100000000,100000000) ops and (56528.1,56528.1) ops/second in (1769.031956,1769.031956) seconds
100000000 operations have been finished (13733.014 MB data have been written into db)

                               Compactions
Level  Files Size(MB) Time(sec) Read(MB) Write(MB)
--------------------------------------------------
  0        1        1       561        0     13804
  1        0        0       311    13802      3958
  2        2        2       117     3958      3297
  3        3        3        88     3300      2748
  4       11        9        61     2751      2293
  5       44       15        75     2435      2037
  6      333      880       250     8083      7101
WriteAmplification: 2.5528

